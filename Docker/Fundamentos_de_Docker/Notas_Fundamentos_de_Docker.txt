Docker es Open Source, que facilita el desarrollo.
Docker no es para dar los primeros pasos en programación sino para resolver problemas que van mas alla de solo la escritura de código logrando hacer el trabajo de 3 personas de hace 10 años con una sola persona.
Docker es un proyecto lanzado en el 2013 que de forma flexible ayuda al despliegue de aplicaciones dentro de contenedores de software, dentro de sus características más importantes se incluye el hecho de que no requiere de utilizar un sistema operativo independiente, lo que lo hace más ligero y rápido, para esto, cuenta con funcionalidades Kernel de Linux ; además de esto Docker posee una manera característica para hacer uso de los elementos de tu equipo, sin necesidad de mayor configuración.
Problemas al construir:
-Dependencias de desarrollo.
-Versiones de entornos de ejecución.
-Equivalencia de entornos de desarrollo.
-Equivalencia de entornos de producción.
-Versiones / compatibilidad.
Problemas al Distribuir:
-Generaciones del build diferentes.
-Acceso a servidores de producción.
-Ejecución nativa vs la distribuida.
-Serverless.
Problemas al Ejecutar:
-Dependencias de aplicación.
-Compatibilidad de sistema operativo.
-Disponibilidad de servicios externos.
-Recursos de hardware.
Docker permite:
Construir, distribuir y correr tu código en cualquier lado.
Al construir código tiene dependencias pues no solo es escribir código sino depender de programas, librerias, versiones.
Otro problema común es cuando un programa corre en tu pc pero no en la de alguien más por las dependencias que tiene.
Al ejecutar hay que considerar al servidor que tiene que correr varias versiones a la vez, el hardware que tiene disponible, el sistema operativo.
Docker permite distribuir, construir y ejecutar el código en cualquier lado sin problemas.
¿Qué es Docker?
-Docker Permite resolver problemas de construir, distribuir y ejecutar software en diferentes plataformas.
Containarization: un estándar para llevar algo dentro. Agrupadores de procesos.
Versátiles:
-En el orden de los MB.
-Tienen todas las dependencias que necesitan para funcionar correctamente.
-Funcionan igual en todos lados.
Eficientes:
-Comparten archivos simultáneos con otros contenedores.
-Solo se ejecutan procesos, no un S.O. completo.
Aislados:
-Lo que pasa en el container queda en el container.
-No pueden alterar su entorno de ejecución (a menos que explícitamente se indique lo contrario).
Virtualization: es una imagen o archivo que contiene información dentro. Por lo general son pesadas de administración costosa y son lentas.
Pesadas:
-En el orden de los GB.
-Muchas VMs en el mismo host suelen repetirse en lo que contienen.
Administración costosa:
-Una VM tiene que ser administrada como cualquier otra computadora: patching, update, etc.
-Hay que administrar la seguridad interna entre apps.
Lentas:
-Correr nuestro código en una VM implica no solo arrancar aplicaciones, sino también esperar el boot de la VM en sí.
Los contenedores son agrupaciones de procesos que están aislados de toda la máquina, parecidas a máquinas virtuales, pero muy distintas.
Para descargar docker se debe instalar docker community for windows y registrarnos en la página de docker.
Se puede configurar cuanta memoria y cpu puede usar docker.
docker --version //Muestra la version.
docker info //Muestra información de docker.
docker necesita windows 10 pro para poder ejecutarse correctamente.
Si se tiene menos de 8gb de ram es mejor iniciar con docker apagado.
Al ejecutar docker run hello-world, si docker no encuentra localmente la imagen entonces la busca en la web, la descarga y corre la aplicación.
La siguiente vez que se ejecute ya no lo descarga sino que usa lo que tiene localmente.
La arquitectura de docker funciona con un cliente que le hace la petición al servicio de docker(daemon), este servicio se encarga de levantar cada contenedor y ponerlo en ejecución, por lo cual el servicio de docker puede estar corriendo en una máquina distinta a la del cliente sin problemas.
Un contenedor ejecuta sus procesos de forma nativa como si fuera cualquier otro proceso del SO, los procesos que se ejecutan dentro del contenedor no pueden ver afuera del contenedor.
Los contenedores no pueden disponer de mas memoria que la asignada.
El único software que se comparte entre docker y el SO es el kernel.
En los servidores productivos de docker se usa Linux ya que ahi corre nativamente en mac y windows hace un tipo de virtualización.
Para un contenedor el root o su ruta origen es donde se empieza a ejecutar el contenedor, no sabrá si existe algún archivo en otra parte de la pc.
https://itnext.io/chroot-cgroups-and-namespaces-an-overview-37124d995e3d
docker ps -a //Nos muestra todos los contenedores aún los que ya terminaron.
docker inspect e0b9d623ad6a//Nos da la información del contenedor dado su id o nombre, con eso podemos saber información del contenedor al momento de programar.
docker ps = lista los contenedores
docker ps -a = lista contenedores a detalles
docker ps -aq = lista solo los ID de los contenedores (la q significa quiet, tranquilo o silencioso)
docker inspect id_contenedor = detalles internos del contenedor
docker inspect nombre_contenedor = lo mismo que el anterior pero para nombre
docker inspect -f {{}} nombre_contenedor = filtra una variable especifica del contenedor
docker rm nombre_contenedor = elimina un contenedor
docker rm $(ps -aq) = borra TODOS los contenedores que no se esten ejecutando.
Listar contendores en ejecución
docker ps
Listar todos los contenedores
docker ps -a
Cargar / Ejecutar una imagen de contenedor
docker run [image]
“image” es la fuente del contenedor.
Cargar / Ejecutar una imagen de contenedor con un nombre específico
docker run --name [name a asignar] [image]
Ver metadatos de un contenedor
docker inspect [name/id contenedor]
Ver un dato exacto de los metadatos de un contenedor:
docker inspect -f '{{ json .Config.Env }}' [name/id]
docker inspect -f "{{ json .Config.Env }}" [name/id]// En windows.
Aquí se utiliza el template de filtro del leguaje GO que es el lenguaje en que fue programado DOCKER.
LINUX … ver el path
echo $PATH
Cambiar el nombre de un contendor descargado
docker rename [name actual] [name nuevo]
Ver las salidas de contenedores ya ejecutados o cargados
docker logs [name/id]
Obtener como salida sólo los ID de los contendores cargados
docker ps -aq
Eliminar / Desmantelar contenedores
docker rm [name/id]
Para eliminar/desmantelar todos los contenedores cargados, utilizamos el comando que nos genera la salida de todos los ID de contendores cargados dentro de un docker rm y el comando quedaría así:
docker rm $(docker ps -aq)
Las rutas nombradas son con respecto al contenedor y no con respecto a la ruta de la pc principal.
docker run genera un contenedor nuevo a partir de una imagen.
docker permite correr un ubuntu con solo ejecutar una instrucción.
Para poder correr el ubuntu necesita una ejecución interactiva pues ubuntu recibe parámetros por la terminal, pero al no tener ninguna entrada por defecto se sale pues no tiene nada que procesar.
docker run -it ubuntu//Ejecuta ubuntu en un contenedor de manera interactiva.
Con cat /etc/lsb-release podemos ver la versión de linux usada.
Con exit se sale del modo interactivo de bash (consola de ubuntu).
El significado de las flags -it:
-t: Asignar un pseudo-tty (Terminal).
-i: mantén STDIN abierto incluso si no está conectado.
docker run ubuntu tail -f /dev/null —> Para no ejecutar el comando por defecto, le podemos decir que se ejecute y no se apague. La terminal se queda congelada.
Abrir otra terminal
docker ps —> para obtener nombre
docker exec -it <nombre contenedor> bash —> Exec es para ejecutar un comando en un contenedor existente, -it para que sea de forma interactiva.
docker exec -it <nombre contenedor> <comando> —> Exec es para ejecutar un comando en un contenedor existente, -it para que sea de forma interactiva.
ps —> En linux se pueden ver los procesos con ps, solo los de mi sesión.
ps -fea —> Para ver procesos de todas las sesiones. Docker siempre por defecto le asigna el PID (ID del proceso) 1 al comando que corre con el contenedor, ahi esta la clave de cuando se apaga el contenedor. Todo contenedor tiene un root COMMAND, cuando haga exit se va apagar el contenedor.
exit —> Salir del contenedor. Puedo hacer 2 cosas:
docker rm -f <nombre contenedor> Elima brutalmente el contenedor. El -f significa “Si esta corriendo no me importa”.
docker kill <nombre contenedor> Manda una señal de matar el proceso.
Si un contenedor se apaga es porque hubo un error en el proceso root e hizo exit o terminó de hacer lo que tenia que hacer.
En docker el proceso principal o el primero siempre es el contenedor con PID 1 si este termina el contenedor deja de ejecutarse.
-d: --detach: Impide que la terminal se quede congelada y de este modo aun cuando el proceso se este ejecutando tenemos control sobre la terminal.
sha256: Es el algoritmo que usa para generar los identificadores únicos.
Los contenedores están aislados del sistema esto tambíen se considera en los puertos del contenedor.
Para conectar un puerto del contenedor a la máquina donde se trabaja se debe especificar el puerto a conectar de la máquina huesped.
-p [puerto_máquina]:[puerto_del_contenedor]//Crea un enlace entre el puerto de la máquina y del puerto del contendor.
docker run -d --name server -p 8080:80 nginx//Levanta el servidor con nginx con control de la terminal enlazando el puerto local al puerto del contenedor.
docker run -d --name dbmongo mongo//Crea un contenedor con mongo db.
docker logs dbmongo// Nos muestra los logs de un contenedor con mongo db.
docker exec -it dbmongo bash //Ejecuta el contenedor con una terminal bash.
mongo//Dentro de la terminal accede a los comandos de mongo.
use platzi//Crea una nueva base de datos.
db.users.insert({ "name": "Luis Fernando" })//Inserta una fila nueva dentro de la tabla.
db.users.find()//Lista todos los elementos de la tabla.
Con el contendor de mongo se puede insertar datos en la base de datos pero al momento de terminar la ejecución del contenedor o eliminarlo se pierden los datos ya que el contenedor está aislado, esto se puede evitar haciendo un enlace (bind) entre la ruta del contenedor y una de la máquina local.
docker run --name dbmongo -d -v /Users/lfzar/docker/mongodata:"/data/db" mongo //Compartir un directorio local con uno del contenedor -v indica el volumen.
Colocar la dirección sin el nombre del disco (C).
bind mount es el tipo de compartir directorios por defecto de docker.
Usar bind mount (rutas enlazadas o espejeadas) es fácil de usar pero puede ser vulnerable a escritura por parte de otros procesos lo cual puede ser peligroso.
Otra forma de persistir los es usando directamente volume, que igual guarda en el sistema de archivos de la pc, pero la ruta es asignada por docker para evitar ser encontrada fácilmente, la ultima forma es usando una memoria temporal con tmpfs. 
docker volume ls//Lista todos los volumenes locales.
docker run -d --name db --mount src=dbdata,dst=/data/db mongo //Crear contenedor de mongo con un el volumen dbdata y la carpeta del contenedor /data/db.
Con los volumenes se puede asignar a una nube para asi tener persistencia de datos en la nube.
https://docs.docker.com/storage/
Las imágenes son un componente fundamental de Docker y sin ellas los contenedores no tendrían sentido. Estas imágenes son fundamentalmente plantillas o templates.
Algo que debemos tener en cuenta es que las imágenes no van a cambiar, es decir, una vez este realizada no la podremos cambiar.
Las imágenes pueden distribuirse de manera muy simple, pues con el nombre de la imagen y docker run puede correrla.
Una imagen siempre parte de una capa base (que a su vez es una imagen), siendo cada capa una diferencia ya sea en archivos agregados, modificados o eliminados de la anterior capa (modelo atómico), con lo cual una imagen descarga solo lo que le hace falta o necesita para completarse.
Cada pull complete representa una capa descargada, que a su vez se pueden descargar en paralelo pero deben ser compiladas en serie, lo que hace mas rapido el proceso.
docker image ls //Lista todas las imágenes.
El tag es un identificador con el que se sabe que versión es.
Antes de decargar cada capa docker verifica si no la tiene con base a su identificador único, si la tiene no la baja de nuevo.
Eliminar imágenes descargadas en el host:
docker image ls // para obtener el id de la imágen.
REPOSITORY TAG IMAGE ID CREATED SIZE
ubuntu 18.04 93fd78260bd1 8 days ago 86.2MB
docker rmi -f 93fd78260bd1
-f => forzar
Ej: docker rmi -f 93fd78260bd1
Para construir una imagen se debe hacer un archivo dockerfile
docker build -t ubuntu:mi_version . //Ejecuta el dockerfile de la carpeta donde se encuentre en la terminal (El "." sirve para indicar a build donde compilar).
Contenido de Dockerfile (sin extensión)
    # Imagen Base
    FROM ubuntu 
    # Comandos a ejecutar
    RUN touch /usr/src/hola-mundo-mundial
Para crear un contenedor primero se tiene un dockerfile ahi se dan las instrucciones para crear la imagen y a partir de la imagen se crea el contenedor.
docker run -it ubuntu:mi_version//Crear contenedor a partir de versión propia.
Por defecto docker usa el repositorio [docker.io/library/ubuntu] para intentar descargar imágenes, cuando lista repositorios de library no muestra toda la extensión.
docker usa el concepto de tag para saber a que repositorio se quiere hacer push.
docker tag [imagen] [nombre_tag(repositorio+tag)].
docker tag ubuntu:mi_version lfzarazuaa/ubuntu:mi_version//Crea imagen con nuevo tag y nombre de repositorio para poderse publicar online.
docker login//Acceder como usuario para modificar repositorios.
docker push lfzarazuaa/ubuntu:mi_version//Publicar el repositorio online.
Docker hub permite repositorios privados pero son de paga.
"From scratch" es la capa más básica que solo contiene la imágen del kernel de linux.
docker history ubuntu:mi_version//Historial de la imagen con versión.
docker history --no-trunc ubuntu:mi_version//Historial de la imagen con versión sin truncar los datos.
docker pull wagoodman/dive //Bajar la imagen:
docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock wagoodman/dive:latest ubuntu:platzi //Cuando se ejecute, deberá incluir el archivo de socket docker.
Dockerfile para aplicación con node js.
    #Usa node js como imagen base.
    FROM node:8
    #Copia del contexto de build (root) a la ruta /usr/src/ para poner datos de usuario.
    COPY [".", "/usr/src/"]
    #Quita el paquete json.
    RUN rm package-lock.json //Línea extra.
    #Cambia el apuntador a ese directorio y lo establece como de trabajo (para correr npm install).
    WORKDIR /usr/src
    #Para ejecutar node.
    RUN npm install
    #Para trabajar con el puerto 3000.
    EXPOSE 3000
    #COMAND Comando por defecto que va a correr la imagen (lo que se ejecuta al hacer docker run).
    CMD ["node", "index.js"]
docker run --rm -p 3000:3000 platziapp //Ejecuta el contenedor con la imagen platziapp pero al tener --rm  lo remueve o elimina al terminar su ejecución.
Cuando en el contexto de build del dockerfile hay cosas que cambian poco se tarda menos en recontruir ya que hace uso de la memoria cache.
Para conectar un contenedor a la base de datos en otro puerto al ser un contenedor y estar aislado se puede crear un contenedor para la aplicación otro para la base de datos y enlazar cada uno a un puerto de la máquina huésped, otra solución es crear una red interna entre los dos contenedores.
docker network ls//Nos da los nombres de las redes de docker.
docker network create --attachable platzinet//Crea la red platzinet con --attachable para tener la posibilidad que contenedores futuros se conecten a la red.
docker network connect platzinet db//Conecta el contenedor de la base de datos a la red.
docker run -d --name app -p 3000:3000 --env MONGO_URL=mongodb://db:27017/test platzinode10//Crea el contenedor definiendo la variable de entorno para la red --env MONGO_URL=mongodb://db:27017/test.
Borrar una red en docker.
docker network rm <nombre de la red>.
Ej: docker network rm platzinet.
Crear una red en docker.
docker network create --attachable <nombre de la red>.
—attachable es para que otros contenedores se puedan unir a esta red.
Ej: docker network create --attachable platzinet.
Ver redes disponibles docker.
docker network ls.
bridge red por defecto y se conectan con un keyword link esta en desuso, compatibilidad (deprecated).
host simula la red del computador que corre docker (no usar).
none hacer que tenga el network deshabilitado.
Ver contenedores en un red.
docker network inspect <nombre de la red>.
Ej: docker network inspect platzinet.
Detallar la búsqueda.
docker network inspect -f '{{.Containers}}' platzinet.
Unir un contenedor a la red creada.
docker network connect <nombre de la red> <nombre del contenedor>.
Ej: docker network connect platzinet db.
docker run -d --name app -p 3000:3000 --env MONGO_URL=mongodb://db:27017/test platziapp.
-env variable de entorno.
db es el nombre del contenedor sin necesidad de pasar la ip del contenedor para la conexión.
Docker compose es una herramienta que permite describir de forma declarativa la arquitectura de nuestra aplicación.
Docker compose usa un archivo .yml para describir la aplicación.
Docker compose tiene varias versiones que se específican con "version: "3"".
Para listar contenedores se usan servicios cada servicio tiene un contenedor, pero se pueden listar varios servicios.
Dockercompose.yml 
    # Específica la versión de docker compose.
    version: "3"
    # Declara que servicios o como será la arquitectura de la aplicación.
    services:
    #Crear contenedor app para la aplicación.
    app:
        #Contenedor basado en la imagen platzinode10
        image: platzinode10
        #Declara la variable de entorno que tendrá app para conectarse a la base de datos.
        environment:
        MONGO_URL: "mongodb://db:27017/test"
        #Específica que el contenedor depende de db (inicializa primero db).
        depends_on:
        - db
        #Enlaza el puerto del contenedor con el de la máquina local.
        ports:
        - "3000:3000"
    #Crear contenedor db para la base de datos.
    db:
        #Contenedor basado en la imagen mongo.
        image: mongo
docker-compose up //Realiza la ejecución de los contenedores descritos en el archivo .yml el cual nos dice la arquitectura de los servicios, para esto se necesita estar en la carpeta de donde tomará los archivos o la específicada según el archivo .yml (contexto de build).
docker-compose up -d//Ejecución de contendores sin mostrar los logs.
docker-compose logs app//Muestra los logs del contenedor app.
docker-compose exec app bash//Explora con bash el servicio(app).
Por defecto docker-compose crea un network para conectar los servicios (contenedores).
Para que docker use el cache debe estar en el mismo repositorio y con la misma capa.
docker-compose build//Hace el build para generar las imágenes faltantes si así se específico en el archivo .yml.
Las imágenes <none> son imágenes que fueron sustituidas por una nueva y ahora quedan sin uso, se recomienda eliminarlas.
docker-compose up -d//Se puede usar si en un servicio tiene build en el .yml ya que compilará las imágenes necesarias y luego las usará.
Se pueden configurar los volúmenes para hacer persistentes los datos y ejecutar cambios en el sistemas de archivos que se reflejen en el contenedor.
docker-compose up permite volver a ejecutarse aún corriendo los contendores.
docker-compose up --scale app=5 //Corre 5 contenedores de tipo app.
Docker-compose.yml para escuchar por varios puertos, con build y volúmenes.
# Específica la versión de docker compose.
version: "3"
# Declara que servicios o como será la arquitectura de la aplicación.
    services:
    #Crear contenedor app para la aplicación.
    app:
        #Construir la imagen a partir del directorio base donde se ejecutó docker-compose.
        build: .
        #Declara la variable de entorno que tendrá app para conectarse a la base de datos.
        environment:
        MONGO_URL: "mongodb://db:27017/test"
        #Específica que el contenedor depende de db (inicializa primero db).
        depends_on:
        - db
        #Enlaza el puerto del contenedor con el de la máquina local.
        ports:
        - "3000-3005:3000"
        #Lista los directorios compartidos con la máquina local.
        volumes: 
        #Comparte el directorio root con la carpeta /usr/src/
        - .:/usr/src/
        #Excluye de la sincronización los archivos de dependencias de la carpeta base /usr/src/ evitando que cuando se sincronice se borre la carpeta.
        - /usr/src/node_modules
    #Crear contenedor db para la base de datos.
    db:
        #Contenedor basado en la imagen mongo.
        image: mongo
docker build -t platziapp -f build/production.Dockerfile . //Crea imagen a partir de un dockerfile explícito, usado para desarrollo y para producción usualmente.
https://medium.com/@serrodcal/construcci%C3%B3n-de-im%C3%A1genes-docker-en-m%C3%BAltiples-etapas-7933179a3e1f
https://docs.docker.com/develop/develop-images/multistage-build/
Docker puede realizar la compilación multicapas lo que permite crear un contenedor de desarrollo donde se pueden correr todos los test y posteriormente eliminar esos test y dependencias solo usadas en desarrollo para implementar la imagen de producción ya comprobada pero mas liviana.
docker build -t platziapp -f build/production.Dockerfile . //Imagen con dockerfile específicado.
production.Dockerfile //Dockerfile de producción con etapa de desarrollo para probar código y de producción para solo tener lo esencial.
    #Primera etapa
    #Capa a partir de node10 que crea contexto llamado builder (contenido del primer contenedor).
    FROM node:10 as builder
    #Copia solo los archivos para las dependencias de node.
    COPY ["package.json", "package-lock.json", "/usr/src/"]
    #Establece como directorio de trabajo o principal /usr/src
    WORKDIR /usr/src
    #Instala dependencias de producción.
    RUN npm install --only=production
    #Copia los archivos faltantes (código propio del proyecto).
    COPY [".", "/usr/src/"]
    #Instala dependencias de desarrollo para realizar testing.
    RUN npm install --only=development
    #Realiza el test de la aplicación (si este comando corre bien se ejecutan lo demás).
    RUN npm run test

    #Segunda capa.
    #Reinicia desde donde comenzar.
    FROM node:10
    #Copia solo los archivos para las dependencias de node.
    COPY ["package.json", "package-lock.json", "/usr/src/"]
    #Establece como directorio de trabajo o principal /usr/src
    WORKDIR /usr/src
    #Instala dependencias de producción.
    RUN npm install --only=production
    #Copia de la primera etapa solo el código propio del proyecto (index.js).
    COPY --from=builder ["/usr/src/index.js", "/usr/src/"]
    #Declara que va a correr en el puerto 3000 del contenedor.
    EXPOSE 3000
    #Ejecuta el comando para levantar el servidor de nuestra aplicación.
    CMD ["node", "index.js"]
Docker in Docker
Docker in Docker nos da la posibilidad de correr comandos de docker dentro de un contenedor de docker.
docker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock docker:18.06.1-ce //Permite correr docker con un volumen que hace referencia al docker local.